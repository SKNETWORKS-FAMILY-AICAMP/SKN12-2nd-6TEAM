{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f7ba3-9136-4d5b-b5da-f94ed6273786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'    #사용 방법1\n",
    "plt.rc('font', family='NanumBarunGothic', size=11) #사용 방법2\n",
    "print(plt.rcParams['font.family'], plt.rcParams['font.size'])   # 폰트확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7a727f-a39c-4c10-9ca3-e1ff463fea06",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 14.7/15.8 MB 102.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 49.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "Successfully installed numpy-1.26.4\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.2 (from autogluon)\n",
      "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
      "  Downloading autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.15.2)\n",
      "Collecting scikit-learn<1.5.3,>=1.4.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.2)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.67.1)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.3)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10.0)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading boto3-1.37.35-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading ray-2.39.0-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.core[all]==1.2->autogluon) (19.0.0)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: Pillow<12,>=10.0.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (11.1.0)\n",
      "Collecting torch<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting transformers<5,>=4.38.0 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torchvision<0.21.0,>=0.16.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting scikit-image<0.25.0,>=0.19.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading scikit_image-0.24.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.1.6)\n",
      "Requirement already satisfied: tensorboard<3,>=2.9 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.19.0)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading catboost-1.2.8-cp311-cp311-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting spacy<3.8 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy-3.7.5-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting lightgbm<4.6,>=4.0 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting einops<0.9,>=0.7 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting xgboost<2.2,>=1.6 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastai-2.7.19-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting huggingface-hub[torch] (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
      "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading gluonts-0.16.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading statsforecast-1.7.8-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading coreforecast-0.0.12-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading orjson-3.10.16-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (5.9.0)\n",
      "Collecting cloudpickle (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2025.3.2)\n",
      "Collecting numba (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading numba-0.61.2-cp311-cp311-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting optuna (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (24.2)\n",
      "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.35 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading botocore-1.37.35-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting plotly (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.17.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pip in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (25.0)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastcore-1.7.29-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pydantic<3,>=1.7 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.12.2)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.22.3)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.9.0.post0)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (8.1.8)\n",
      "Collecting regex>=2021.8.3 (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.4.6)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (14.0.0)\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.18.0)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.29.4)\n",
      "Collecting aiosignal (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting aiohttp>=3.7 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohttp-3.11.16-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.21.1)\n",
      "Collecting smart-open (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading virtualenv-20.30.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.71.0)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2025.1.31)\n",
      "Collecting imageio>=2.33 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tifffile-2025.3.30-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.5.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading thinc-8.2.5-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (75.8.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading statsmodels-0.14.4-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (4.12.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.19.1)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.3.7)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.17.2)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pycryptodome-3.22.0-cp37-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (308)\n",
      "Collecting alembic>=1.5.0 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.31.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (2.5)\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (1.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.5.1)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
      "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
      "Downloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
      "Downloading autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
      "Downloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
      "Downloading autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
      "Downloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
      "Downloading coreforecast-0.0.12-py3-none-win_amd64.whl (101 kB)\n",
      "Downloading mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Downloading boto3-1.37.35-py3-none-any.whl (139 kB)\n",
      "Downloading catboost-1.2.8-cp311-cp311-win_amd64.whl (102.5 MB)\n",
      "   ---------------------------------------- 0.0/102.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 6.3/102.5 MB 128.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 16.0/102.5 MB 38.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 32.2/102.5 MB 52.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 55.3/102.5 MB 66.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 79.2/102.5 MB 76.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 94.1/102.5 MB 75.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  102.2/102.5 MB 76.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 102.5/102.5 MB 68.1 MB/s eta 0:00:00\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading fastai-2.7.19-py3-none-any.whl (234 kB)\n",
      "Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Downloading gluonts-0.16.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 26.7 MB/s eta 0:00:00\n",
      "Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 82.6 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
      "   ---------------------------------------- 0.0/818.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 818.9/818.9 kB 37.1 MB/s eta 0:00:00\n",
      "Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 40.3 MB/s eta 0:00:00\n",
      "Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Downloading orjson-3.10.16-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "Downloading ray-2.39.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 12.6/25.1 MB 87.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.3/25.1 MB 37.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.0/25.1 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 34.5 MB/s eta 0:00:00\n",
      "Downloading scikit_image-0.24.0-cp311-cp311-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 4.2/12.8 MB 18.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 33.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.0/11.0 MB 86.0 MB/s eta 0:00:00\n",
      "Downloading spacy-3.7.5-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 7.3/12.1 MB 114.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.4/12.1 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading statsforecast-1.7.8-cp311-cp311-win_amd64.whl (254 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 65.1 MB/s eta 0:00:00\n",
      "Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---- ---------------------------------- 24.9/203.1 MB 112.5 MB/s eta 0:00:02\n",
      "   --------- ----------------------------- 49.5/203.1 MB 116.8 MB/s eta 0:00:02\n",
      "   ------------- ------------------------- 68.2/203.1 MB 114.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 77.3/203.1 MB 89.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 93.8/203.1 MB 86.7 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 115.1/203.1 MB 88.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 137.4/203.1 MB 91.4 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 155.7/203.1 MB 91.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 161.7/203.1 MB 86.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 170.1/203.1 MB 80.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 184.3/203.1 MB 78.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 79.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 79.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.1/203.1 MB 69.4 MB/s eta 0:00:00\n",
      "Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "   ---------------------------------------- 0.0/806.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 806.1/806.1 kB 34.0 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 81.3 MB/s eta 0:00:00\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.4/10.4 MB 92.9 MB/s eta 0:00:00\n",
      "Downloading utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 16.8/124.9 MB 88.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 27.3/124.9 MB 86.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 28.6/124.9 MB 46.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 52.2/124.9 MB 61.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 76.0/124.9 MB 72.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 85.2/124.9 MB 67.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 92.5/124.9 MB 63.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 106.7/124.9 MB 63.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 114.8/124.9 MB 61.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 117.7/124.9 MB 56.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  123.2/124.9 MB 53.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 52.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 47.8 MB/s eta 0:00:00\n",
      "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
      "   ---------------------------------------- 0.0/823.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 823.0/823.0 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading aiohttp-3.11.16-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading botocore-1.37.35-py3-none-any.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 13.5/13.5 MB 105.8 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fastcore-1.7.29-py3-none-any.whl (84 kB)\n",
      "Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl (74 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 40.8 MB/s eta 0:00:00\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "Downloading py_spy-0.4.0-py2.py3-none-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 96.8 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 105.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 991.5/991.5 kB ? eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 632.6/632.6 kB 23.2 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.4-cp311-cp311-win_amd64.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 9.9/9.9 MB 87.2 MB/s eta 0:00:00\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading thinc-8.2.5-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 39.3 MB/s eta 0:00:00\n",
      "Downloading tifffile-2025.3.30-py3-none-any.whl (226 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 70.1 MB/s eta 0:00:00\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading virtualenv-20.30.0-py3-none-any.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 131.2 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 14.8/14.8 MB 92.6 MB/s eta 0:00:00\n",
      "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.6/6.6 MB 102.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.4 MB 114.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-win_amd64.whl (30.3 MB)\n",
      "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 13.1/30.3 MB 63.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.1/30.3 MB 76.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.3/30.3 MB 68.7 MB/s eta 0:00:00\n",
      "Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 123.2 MB/s eta 0:00:00\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading pycryptodome-3.22.0-cp37-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 102.2 MB/s eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl (295 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): started\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19219 sha256=7f02f0b2795b6fe20e6443be151b62157c70ca58a054c65f88552ba4af163e65\n",
      "  Stored in directory: c:\\users\\playdata\\appdata\\local\\pip\\cache\\wheels\\47\\50\\9e\\29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144615 sha256=3f2b5b77cffce101cf4e7c100ba43f3ce367e5abc8980cc8f9c038af80927efd\n",
      "  Stored in directory: c:\\users\\playdata\\appdata\\local\\pip\\cache\\wheels\\1a\\97\\32\\461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16247 sha256=f6cdce780dc1dabdbb5a9b19f6d42965348ee2ccdadbf6f49012e6a040f8bdec\n",
      "  Stored in directory: c:\\users\\playdata\\appdata\\local\\pip\\cache\\wheels\\bc\\92\\f0\\243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
      "Installing collected packages: text-unidecode, sentencepiece, py4j, py-spy, opencensus-context, nvidia-ml-py3, distlib, cymem, appdirs, antlr4-python3-runtime, xxhash, wasabi, virtualenv, typing-inspection, toolz, tifffile, tensorboardX, tabulate, spacy-loggers, spacy-legacy, smart-open, shellingham, safetensors, regex, pytesseract, pydantic-core, pycryptodome, pyasn1, proto-plus, propcache, plotly, pdf2image, patsy, orjson, ordered-set, openxlab, omegaconf, murmurhash, multidict, msgpack, marisa-trie, Mako, llvmlite, lightning-utilities, lazy-loader, jmespath, imageio, greenlet, graphviz, googleapis-common-protos, future, fsspec, fs, frozenlist, fastprogress, fastcore, einops, dill, coreforecast, colorlog, colorful, cloudpickle, cloudpathlib, catalogue, blis, annotated-types, aiohappyeyeballs, yarl, xgboost, torch, srsly, sqlalchemy, scikit-learn, scikit-image, rsa, pydantic, pyasn1-modules, preshed, numba, nltk, multiprocess, model-index, lightgbm, language-data, hyperopt, huggingface-hub, fastdownload, botocore, aiosignal, window-ops, utilsforecast, typer, triad, torchvision, torchmetrics, tokenizers, statsmodels, seqeval, s3transfer, pytorch-metric-learning, opendatalab, langcodes, jsonschema, google-auth, gluonts, gdown, confection, catboost, alembic, aiohttp, accelerate, weasel, transformers, timm, thinc, ray, optuna, openmim, nlpaug, google-api-core, boto3, aiohttp-cors, adagio, spacy, pytorch-lightning, opencensus, mlforecast, fugue, datasets, autogluon.common, statsforecast, lightning, fastai, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0\n",
      "    Uninstalling torch-2.6.0:\n",
      "      Successfully uninstalled torch-2.6.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0\n",
      "    Uninstalling torchvision-0.21.0:\n",
      "      Successfully uninstalled torchvision-0.21.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.23.0\n",
      "    Uninstalling jsonschema-4.23.0:\n",
      "      Successfully uninstalled jsonschema-4.23.0\n",
      "Successfully installed Mako-1.3.10 accelerate-0.34.2 adagio-0.2.6 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiohttp-cors-0.8.1 aiosignal-1.3.2 alembic-1.15.2 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 blis-0.7.11 boto3-1.37.35 botocore-1.37.35 catalogue-2.0.10 catboost-1.2.8 cloudpathlib-0.21.0 cloudpickle-3.1.1 colorful-0.5.6 colorlog-6.9.0 confection-0.1.5 coreforecast-0.0.12 cymem-2.0.11 datasets-3.5.0 dill-0.3.8 distlib-0.3.9 einops-0.8.1 evaluate-0.4.3 fastai-2.7.19 fastcore-1.7.29 fastdownload-0.0.7 fastprogress-1.0.3 frozenlist-1.5.0 fs-2.4.16 fsspec-2024.12.0 fugue-0.9.1 future-1.0.0 gdown-5.2.0 gluonts-0.16.1 google-api-core-2.24.2 google-auth-2.39.0 googleapis-common-protos-1.70.0 graphviz-0.20.3 greenlet-3.2.0 huggingface-hub-0.30.2 hyperopt-0.2.7 imageio-2.37.0 jmespath-1.0.1 jsonschema-4.21.1 langcodes-3.5.0 language-data-1.3.0 lazy-loader-0.4 lightgbm-4.5.0 lightning-2.5.1 lightning-utilities-0.14.3 llvmlite-0.44.0 marisa-trie-1.2.1 mlforecast-0.13.4 model-index-0.1.11 msgpack-1.1.0 multidict-6.4.3 multiprocess-0.70.16 murmurhash-1.0.12 nlpaug-1.1.11 nltk-3.8.1 numba-0.61.2 nvidia-ml-py3-7.352.0 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.3.0 ordered-set-4.1.0 orjson-3.10.16 patsy-1.0.1 pdf2image-1.17.0 plotly-6.0.1 preshed-3.0.9 propcache-0.3.1 proto-plus-1.26.1 py-spy-0.4.0 py4j-0.10.9.9 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycryptodome-3.22.0 pydantic-2.11.3 pydantic-core-2.33.1 pytesseract-0.3.10 pytorch-lightning-2.5.1 pytorch-metric-learning-2.3.0 ray-2.39.0 regex-2024.11.6 rsa-4.9.1 s3transfer-0.11.4 safetensors-0.5.3 scikit-image-0.24.0 scikit-learn-1.5.2 sentencepiece-0.2.0 seqeval-1.2.2 shellingham-1.5.4 smart-open-7.1.0 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.40 srsly-2.5.1 statsforecast-1.7.8 statsmodels-0.14.4 tabulate-0.9.0 tensorboardX-2.6.2.2 text-unidecode-1.3 thinc-8.2.5 tifffile-2025.3.30 timm-1.0.3 tokenizers-0.21.1 toolz-0.12.1 torch-2.5.1 torchmetrics-1.2.1 torchvision-0.20.1 transformers-4.51.3 triad-0.9.8 typer-0.15.2 typing-inspection-0.4.0 utilsforecast-0.2.4 virtualenv-20.30.0 wasabi-1.1.3 weasel-0.4.1 window-ops-0.0.15 xgboost-2.1.4 xxhash-3.5.0 yarl-1.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Playdata\\AppData\\Local\\miniconda3\\envs\\proj2\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy==1.26.4\n",
    "!pip install -U autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c64c9a6-78d6-4ac6-90b9-110e857dfb6f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\proj2\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70131e86-5983-4ec7-b626-779a6f6665c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting final_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile final_app.py\n",
    "\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import joblib\n",
    "import sys\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score,confusion_matrix\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# 한글 폰트 설정 (Google Colab 또는 로컬에서 실행 시)\n",
    "if sys.platform == \"linux\":\n",
    "    import matplotlib.font_manager as fm\n",
    "    import subprocess\n",
    "    subprocess.run([\"apt-get\", \"-qq\", \"-y\", \"install\", \"fonts-nanum\"], check=True)\n",
    "    font_files = fm.findSystemFonts(fontpaths=['/usr/share/fonts/truetype/nanum'])\n",
    "    for f in font_files:\n",
    "        fm.fontManager.addfont(f)\n",
    "    plt.rc('font', family='NanumBarunGothic')\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "else:\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"고객 이탈 분석 대시보드\", layout=\"wide\")\n",
    "st.title(\"고객 이탈 분석 및 예측\")\n",
    "\n",
    "# 메뉴 선택\n",
    "menu = st.sidebar.radio(\"메뉴를 선택하세요\", [\"개요\", \"데이터 전처리\", \"모델 학습\", \"모델 평가\", \"모델 추론\" ,\"마무리\"])\n",
    "\n",
    "\n",
    "def over_sampling(X,y):\n",
    "    print(y.value_counts())\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    print(y_resampled.value_counts())\n",
    "    print(X.shape, X_resampled.shape)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"data/csv/bank.csv\")\n",
    "    df1 = pd.read_csv(\"data/csv/bb.csv\")\n",
    "    scaler = joblib.load(\"data/scaler.pkl\")\n",
    "    # 모델이 저장된 경로\n",
    "    model_path = 'data/Bank_model_0417'\n",
    "    # 모델 불러오기\n",
    "    model = TabularPredictor.load(model_path)\n",
    "    \n",
    "    return df, df1, scaler, model\n",
    "\n",
    "def makeDf(X,y):\n",
    "  df = pd.DataFrame(X)\n",
    "  df['target'] = y\n",
    "  return df\n",
    "\n",
    "def dataset(df):\n",
    "    X = df.drop(\"이탈여부\", axis=1)\n",
    "    y = df[\"이탈여부\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_train, y_train = over_sampling(X_train,y_train)\n",
    "    y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "    return X,y,X_train, X_test, y_train, y_test\n",
    "    \n",
    "df, df1, scaler, model = load_data()\n",
    "X,y,X_train, X_test, y_train, y_test = dataset(df)\n",
    "df2 = df.copy()  # df2는 df의 복사본으로 시작\n",
    "num_col = ['신용한도', '회전잔액',  '총거래금액' ]\n",
    "\n",
    "df2[num_col] = scaler.inverse_transform(df2[num_col])\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def load_table():\n",
    "    automl_model_scores = pd.read_csv('data/csv/automl_model_scores_wide_format.csv')\n",
    "    nomal_model_scores = pd.read_csv('data/csv/nomal_model_scores_wide_format.csv')\n",
    "    tuning_model_scores = pd.read_csv('data/csv/tuning_model_scores_wide_format.csv')\n",
    "    return automl_model_scores, nomal_model_scores, tuning_model_scores\n",
    "\n",
    "automl_df, nomal_df, tuning_df = load_table()\n",
    "nomal_df.columns.values[0] = 'Model'\n",
    "tuning_df.columns.values[0] = 'Model'\n",
    "automl_df.columns.values[0] = 'Model'\n",
    "\n",
    "##################\n",
    "df_123 = makeDf(X,y)\n",
    "\n",
    "df_train, df_test = train_test_split(df_123, random_state=42)\n",
    "\n",
    "a,b= over_sampling(df_train.drop('target',axis=1), df_train.loc[:,'target'] )\n",
    "df_train = makeDf(a,b )\n",
    "\n",
    "# TabularDataset\n",
    "bank_train = TabularDataset(df_train)\n",
    "bank_test = TabularDataset(df_test)\n",
    "\n",
    "# 예측 값 (클래스 값)\n",
    "pred = model.predict(bank_test)\n",
    "\n",
    "# 예측 확률 (AUC 계산을 위해 필요)\n",
    "proba = model.predict_proba(bank_test)\n",
    "\n",
    "#################333\n",
    "\n",
    "if menu == \"개요\":\n",
    "    st.markdown(\"\"\"\n",
    "고객 이탈 데이터 시각화 및 AI 모델 고객 이탈 가능성 예측\n",
    "\n",
    "## 🎯 프로젝트 목표  \n",
    "- 은행 데이터를 바탕으로 고객 이탈을 예측하고, 이탈 요인을 시각적으로 분석  \n",
    "\n",
    "## 🔍 프로젝트 배경  \n",
    "![이탈 비율](https://i.ibb.co/HTJ6ZqvT/2025-04-17-141405.png)\n",
    "![이탈 비율](https://i.ibb.co/Ps3rDN84/2025-04-17-141434.png)\n",
    "- 주거래은행 이탈 비율이 높아지고 있음\n",
    "    - 시중은행 이탈률: **10.1%**\n",
    "    - 인터넷 전문은행 이탈률: **30.7%**\n",
    "    - 연령이 낮을수록 이탈 비율이 높고 장기적으로 이탈 비율이 증가할 것으로 예상됨\n",
    "\n",
    "![이탈 의향](https://i.ibb.co/YBf4NFp5/2025-04-17-141456.png)\n",
    "- 과반이 넘는 소비자가 **거래 이탈 의향**을 가지고 있음\n",
    "- 따라서 고객 이탙을 막기 위한 **이탈 예측 모델**이 필요함\n",
    "\n",
    "![비대면 대출 갈아타기 서비스](https://img.asiatoday.co.kr/file/2024y/02m/02d/2024020201000169500007791.jpg)\n",
    "- 특히 최근 낮은 금리를 지원하는 **비대면 대출 갈아타기 서비스**로 인해, 비대면 플랫폼으로의 이탈 비율이 높아지고 있음\n",
    "- 때문에 은행 데이터를 기반으로 고객의 이탈을 예측하는 모델은 시의성 측면에서도 적합한 주제임\n",
    "\n",
    "## 📑 데이터  \n",
    "- 출처 : 깃허브 \n",
    "\n",
    "### ✨ 변수 설명\n",
    "| **항목**                 | **설명 (사용자 정의)**              |\n",
    "|----------------------|-------------------------------|\n",
    "| 이탈여부              | 고객이 이탈했는지 여부          |\n",
    "| 부양가족수            | 고객이 부양하는 가족 수         |\n",
    "| 교육수준              | 고객의 교육 수준               |\n",
    "| 총거래관계수          | 고객과 은행 간 전체 거래 항목 수 |\n",
    "| 12개월비활성개월수     | 최근 12개월 동안 비활성 기간(월) 수 |\n",
    "| 12개월고객접촉횟수         | 최근 12개월 동안 고객 접촉 횟수  |\n",
    "| 신용한도                  | 고객의 신용 한도               |\n",
    "| 회전잔액                  | 회전(남은) 잔액               |\n",
    "| 1~4분기총이용금액변화       | 1~4분기 동안의 총 이용금액 변화  |\n",
    "| 총거래금액                | 총 거래 금액                   |\n",
    "| 1~4분기거래횟수변화       | 분기별 거래 횟수의 변화         |\n",
    "| 나이그룹                | 나이 범주형 그룹               |\n",
    "| 수입                   | 고객의 수입 수준               |\n",
    "| 결혼여부        | 고객의 결혼 여부     |\n",
    "| 카드등급        | 고객의 카드 등급            |\n",
    "| 성별               | 고객의 성별                      |\n",
    "\n",
    "\n",
    "**🎉 주요 기능:**  \n",
    "- 이탈 여부 분포 시각화  \n",
    "- 변수별 이탈과의 관계 분석  \n",
    "- 상관관계 히트맵 확인  \n",
    "- 사용자 입력 기반 이탈 예측 시뮬레이션\n",
    "\"\"\")\n",
    "\n",
    "elif menu == \"데이터 전처리\":\n",
    "\n",
    "    st.title(\"데이터 전처리\")\n",
    "    \n",
    "    # 탭 생성\n",
    "    탭1, 탭2, 탭3, 탭4 = st.tabs([\"🔮 피처 엔지니어링\", \"🕶️ 이상치 탐색\", \"🔗 상관관계\", \"🎢 SMOTE\"])\n",
    "    \n",
    "    with 탭1:\n",
    "        st.subheader(\"🔮 피처 엔지니어링\")\n",
    "        st.markdown(\"\"\"\n",
    "## 범주형 데이터 처리\n",
    "### 원-핫 인코딩\n",
    "- 결혼 여부\n",
    "- 카드 등급\n",
    "- 성별\n",
    "\n",
    "## 데이터 구간화\n",
    "\n",
    "### 나이\n",
    "| **나이**    | **나이 구간화**   |\n",
    "|------------|--------|\n",
    "| 0 - 30     | 0      |\n",
    "| 30 - 40    | 1      |\n",
    "| 40 - 50    | 2      |\n",
    "| 50 - 60    | 3      |\n",
    "| 60 - 100   | 4      |\n",
    "\n",
    "\n",
    "### 카드 보유 기간\n",
    "| **카드보유기간(개월)** | **카드보유년 (결과)** |\n",
    "|-------------------|------------------|\n",
    "| 48 이상           | 4                |\n",
    "| 36 이상 48 미만   | 3                |\n",
    "| 24 이상 36 미만   | 2                |\n",
    "| 24 미만           | 1                |\n",
    "\n",
    "### 수입 구간\n",
    "| **수입범주**        | **수입 (결과)** |\n",
    "|-----------------|------------|\n",
    "| Less than $40K  | 1          |\n",
    "| $40K - $60K     | 2          |\n",
    "| $60K - $80K     | 3          |\n",
    "| $80K - $120K    | 4          |\n",
    "| $120K +         | 5          |\n",
    "| Unknown         | 0          |\n",
    "\n",
    "\n",
    "### 교육 수준\n",
    "| **교육수준**        | **매핑된 값 (결과)** |\n",
    "|-----------------|----------------|\n",
    "| Unknown  (알려지지 않음)      | 0              |\n",
    "| Uneducated (중졸 이하)    | 1              |\n",
    "| High School (고졸)    | 2              |\n",
    "| College  (대학 재학)      | 3              |\n",
    "| Graduate  (대졸)     | 4              |\n",
    "| Post-Graduate (석사 학위) | 5              |\n",
    "| Doctorate  (박사 학위)    | 6              |\n",
    "        \"\"\")\n",
    "    \n",
    "    with 탭2:\n",
    "        st.subheader(\"🕶️ 이상치 탐색\")\n",
    "        st.markdown(\"\"\"\n",
    "### 이상치 처리 \n",
    "- RobustScaler \n",
    "    - 중앙값을 기준으로 IQR 방식을 사용하여 스케일링\n",
    "    - 중앙값과 사분위수를 사용하므로 이상치에 민감하지 않음\n",
    "- 은행 데이터에서 금액 관련 변수는 분포의 편차가 크고 이상치의 영향이 커 RobustScaler를 적용하였다.\n",
    "이상치로 판단되는 값을 제거하기에는 데이터 손실 우려가 있어, 보존한 상태에서 정규화 처리하였다. \n",
    "        \"\"\")\n",
    "\n",
    "        # 버튼 클릭 여부 확인\n",
    "        show_outlier = st.button('전처리 이후 데이터 박스플롯 확인')\n",
    "\n",
    "        if not show_outlier:\n",
    "            # 수치형 컬럼 추출\n",
    "            num_col = df1.select_dtypes(include='number').columns\n",
    "            \n",
    "            # 박스플롯 시각화\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            for idx, col in enumerate(num_col):\n",
    "                ax = fig.add_subplot(4, 5, idx + 1)\n",
    "                sns.boxplot(y=df1[col], ax=ax)\n",
    "                ax.set_title(col)\n",
    "                ax.set_ylabel('')\n",
    "            \n",
    "            fig.suptitle(\"전처리 이전 수치형 변수 박스 플롯\", fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            st.pyplot(fig)\n",
    "        else:\n",
    "            # 수치형 컬럼 추출\n",
    "            num_col = df.select_dtypes(include='number').columns\n",
    "            \n",
    "            # 박스플롯 시각화\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            for idx, col in enumerate(num_col):\n",
    "                ax = fig.add_subplot(4, 5, idx + 1)\n",
    "                sns.boxplot(y=df[col], ax=ax)\n",
    "                ax.set_title(col)\n",
    "                ax.set_ylabel('')\n",
    "            \n",
    "            fig.suptitle(\"전처리 이후 수치형 변수 박스 플롯\", fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            st.pyplot(fig)\n",
    "      \n",
    "    with 탭3:\n",
    "        st.subheader(\"🔗 상관관계\")\n",
    "        st.markdown(\"\"\"\n",
    "- 데이터 간의 강한 상관관계를 띄는 변수가 존재함\n",
    "- 상관관계가 0.5이상인 변수들을 제거\n",
    "        \"\"\")\n",
    "        # 페이지 제목\n",
    "        st.title('상관 관계 히트맵')\n",
    "        st.write(\"상관관계가 0.5이상인 변수들 제거 : ['평균사용금액', '평균이용률', '총거래횟수','카드보유년']\")\n",
    "        \n",
    "        # 버튼 클릭 여부 확인\n",
    "        show_df1 = st.button('전처리 이후 데이터 상관관계 확인')\n",
    "        \n",
    "        if not show_df1:\n",
    "            # df 데이터에서 상관계수 계산\n",
    "            columns_to_select1 = ['평균사용가능금액', '평균이용률', '총거래횟수', '카드보유년',\n",
    "                                  '부양가족수', '신용한도', '회전잔액', '총거래금액', '수입',\n",
    "                                  '교육수준', '총거래관계수', '12개월비활성개월수', '12개월고객접촉횟수']\n",
    "            df_selected = df1[columns_to_select1]\n",
    "            \n",
    "            corr = df_selected.corr()\n",
    "        \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "            plt.title(\"DF 데이터 처리전  상관 관계 히트맵\")\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        else:\n",
    "            # df1 데이터에서 상관계수 계산\n",
    "            columns_to_select = ['부양가족수', '신용한도', '회전잔액', '총거래금액',\n",
    "                                 '수입', '교육수준', '총거래관계수', '12개월비활성개월수', '12개월고객접촉횟수']\n",
    "            df1_selected = df[columns_to_select]\n",
    "            \n",
    "            corr = df1_selected.corr()\n",
    "        \n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "            plt.title(\"DF 데이터 처리 후 상관 관계 히트맵\")\n",
    "            st.pyplot(fig)\n",
    "    \n",
    "    with 탭4:\n",
    "        st.subheader(\"🎢 클래스 불균형\")\n",
    "        st.markdown(\"\"\"\n",
    "### 🎢 클래스 불균형 해소\n",
    "- 원본 데이터에서 이탈 여부는 약 8 : 2이다\n",
    "- 이런 클래스 불균형 상황에서는 분류 모델의 성능이 떨어질 수 있다\n",
    "- 이를 해소하기 위해 Train 데이터 셋에서 SMOTE을 이용한 오버 샘플링을 진행했다.\n",
    "        \"\"\")\n",
    "\n",
    "        # 버튼 클릭 여부 확인\n",
    "        show_smote = st.button('클래스 불균형 확인')\n",
    "        \n",
    "        if not show_smote:\n",
    "            # df 데이터에서 상관계수 계산\n",
    "              \n",
    "            # 이탈여부 시각화\n",
    "            fig = plt.figure(figsize=(6, 4))\n",
    "            sns.countplot(data=df, x=\"이탈여부\")\n",
    "            plt.title(\"이탈 여부 분포\")\n",
    "            plt.xlabel(\"이탈여부 (0: 유지, 1: 이탈)\")\n",
    "            plt.ylabel(\"고객 수\")\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "            plt.show()\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        else:\n",
    "            y_train_df = pd.DataFrame(y_train)\n",
    "            fig = plt.figure(figsize=(6, 4))\n",
    "            sns.countplot(data=y_train_df, x=\"이탈여부\")\n",
    "            plt.title(\"이탈 여부 분포\")\n",
    "            plt.xlabel(\"이탈여부 (0: 유지, 1: 이탈)\")\n",
    "            plt.ylabel(\"고객 수\")\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "            plt.show()\n",
    "            st.pyplot(fig)\n",
    "\n",
    "elif menu == \"모델 학습\":\n",
    "    # 탭 생성\n",
    "    # 그래프 탭 추가 (예: tab5)\n",
    "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\n",
    "        \"📘 기본 모델 성능\",\n",
    "        \"📙 튜닝 모델 성능\",\n",
    "        \"📗 AutoML 모델 성능\",\n",
    "        \"📊 기본 vs 튜닝 모델 비교\",\n",
    "        \"📈 모델별 f1 score 비교\"\n",
    "    ])\n",
    "    # f1_test만 추출\n",
    "    f1_nomal = nomal_df[\"f1_test\"]\n",
    "    f1_tuning = tuning_df[\"f1_test\"]\n",
    "    f1_automl = automl_df[\"f1_test\"]\n",
    "    with tab1:\n",
    "        st.subheader(\"📘 기본 모델 성능\")\n",
    "        st.dataframe(nomal_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### 📊 기본 모델별 f1 score\")\n",
    "        \n",
    "        fig1 = px.bar(nomal_df,\n",
    "                      x=\"Model\", y=\"f1_test\",\n",
    "                      text_auto=True,\n",
    "                      title=\"기본 모델의 F1 Score\")\n",
    "        fig1.update_layout(xaxis_title=\"모델\", yaxis_title=\"F1 Score\", title_x=0.5)\n",
    "\n",
    "        st.plotly_chart(fig1, use_container_width=True)\n",
    "    \n",
    "    with tab2:\n",
    "        st.subheader(\"📙 튜닝 모델 성능\")\n",
    "        st.dataframe(tuning_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### 📊 튜닝 모델별 f1 score\")\n",
    "\n",
    "        fig2 = px.bar(tuning_df,\n",
    "                      x=\"Model\", y=\"f1_test\",\n",
    "                      text_auto=True,\n",
    "                      title=\"튜닝 모델의 F1 Score\")\n",
    "        fig2.update_layout(xaxis_title=\"모델\", yaxis_title=\"F1 Score\", title_x=0.5)\n",
    "\n",
    "        st.plotly_chart(fig2, use_container_width=True)\n",
    "    \n",
    "    with tab3:\n",
    "        st.subheader(\"📗 AutoML 모델 성능\")\n",
    "        st.dataframe(automl_df, use_container_width=True)\n",
    "    \n",
    "    with tab4:\n",
    "        st.subheader(\"📈 기본 vs 튜닝 모델 성능 향상률 (%)\")\n",
    "    \n",
    "        metrics = [\"f1_cv\", \"accuracy_cv\", \"precision_cv\", \"roc_auc_cv\", \"recall_cv\",\n",
    "                   \"f1_test\", \"accuracy_test\", \"precision_test\", \"roc_auc_test\", \"recall_test\"]\n",
    "        \n",
    "        # 향상률 계산\n",
    "        improvement_df = ((tuning_df[metrics] - nomal_df[metrics]) / nomal_df[metrics]) * 100\n",
    "        improvement_df = improvement_df.round(2).astype(str) + '%'\n",
    "\n",
    "        # 모델 컬럼 삽입\n",
    "        improvement_df.insert(0, \"Model\", nomal_df[\"Model\"])\n",
    "        \n",
    "        # 데이터 프레임 출력\n",
    "        st.dataframe(improvement_df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"### 📊 모델별 f1 score (튜닝 전 vs 튜닝 후)\")\n",
    "\n",
    "        # 시각화를 위한 데이터 준비\n",
    "        f1_compare_df = pd.DataFrame({\n",
    "            \"Model\": nomal_df[\"Model\"],\n",
    "            \"튜닝 전 (f1_test)\": nomal_df[\"f1_test\"],\n",
    "            \"튜닝 후 (f1_test)\":  tuning_df[\"f1_test\"]\n",
    "        })\n",
    "        \n",
    "\n",
    "        # melt 해서 long-form으로 변환\n",
    "        f1_long_df = f1_compare_df.melt(id_vars=\"Model\", \n",
    "                                        value_vars=[\"튜닝 전 (f1_test)\", \"튜닝 후 (f1_test)\"],\n",
    "                                        var_name=\"구분\", value_name=\"F1 Score\")\n",
    "\n",
    "        # 시각화\n",
    "        fig = px.bar(f1_long_df,\n",
    "                     x=\"Model\", y=\"F1 Score\", color=\"구분\",\n",
    "                     barmode=\"group\", text_auto=True,\n",
    "                     title=\"모델별 F1 Score 비교 (튜닝 전 vs 튜닝 후)\")\n",
    "        fig.update_layout(xaxis_title=\"모델\", yaxis_title=\"F1 Score\", title_x=0.5)\n",
    "\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    with tab5:\n",
    "        st.subheader(\"📗 튜닝 모델 vs AutoML 모델 F1 Score 비교\")\n",
    "    \n",
    "        automl_f1_score = automl_df['f1_test'].values[0]\n",
    "        repeated_automl_scores = [automl_f1_score] * len(tuning_df)\n",
    "    \n",
    "        f1_comparison_df = pd.DataFrame({\n",
    "            'Model': tuning_df['Model'],\n",
    "            'Tuning F1 Score': tuning_df['f1_test'],\n",
    "            'AutoML F1 Score': repeated_automl_scores\n",
    "        })\n",
    "    \n",
    "        st.write(f1_comparison_df)\n",
    "    \n",
    "        # 막대 안쪽으로 수치 표시\n",
    "        fig_f1_comparison = px.bar(f1_comparison_df,\n",
    "                                   x='Model', y=['Tuning F1 Score', 'AutoML F1 Score'],\n",
    "                                   barmode='group',\n",
    "                                   title='튜닝 모델 vs AutoML 모델 F1 Score 비교',\n",
    "                                   text_auto=True)\n",
    "    \n",
    "        # 수치를 막대 내부로 설정\n",
    "        fig_f1_comparison.update_traces(textposition='inside')\n",
    "    \n",
    "        fig_f1_comparison.update_layout(\n",
    "            xaxis_title=\"모델\",\n",
    "            yaxis_title=\"F1 Score\",\n",
    "            title_x=0.5,\n",
    "            xaxis_tickangle=-45\n",
    "        )\n",
    "    \n",
    "        st.plotly_chart(fig_f1_comparison, use_container_width=True)\n",
    "elif menu == \"모델 평가\":\n",
    "    tab1, tab2, tab3, tab4 = st.tabs([\"confusion-matrix\",\"ROC곡선\",\"변수별 중요도\",\"변수 별 이탈여부\"])\n",
    "    \n",
    "    with tab1:\n",
    "        st.subheader(\"confusion-matrix\")\n",
    "        # 예측 수행\n",
    "        \n",
    "        # 혼동 행렬 계산\n",
    "        cm = confusion_matrix(bank_test['target'], pred)\n",
    "        \n",
    "        # Streamlit 시각화\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Pred 0', 'Pred 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'],\n",
    "                    ax=ax)\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('Actual')\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.markdown(\"### 📊 Score Summary\")\n",
    "        st.markdown(f\"\"\"\n",
    "### **Accuracy** : `{accuracy_score(bank_test['target'], pred):.4f}` \n",
    "### **F1 Score** : `{f1_score(bank_test['target'], pred):.4f}`       \n",
    "### **Recall Score** : `{recall_score(bank_test['target'], pred):.4f}`   \n",
    "### **Precision Score** : `{precision_score(bank_test['target'], pred):.4f}`\n",
    "        \"\"\")\n",
    "        \n",
    "    with tab2:\n",
    "        st.subheader(\"ROC곡선\")\n",
    "\n",
    "        # ROC 곡선 계산\n",
    "        fpr, tpr, thresholds = roc_curve(bank_test['target'], proba[1])\n",
    "        \n",
    "        # 그래프 그리기\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.plot(fpr, tpr, color='red', lw=2, label='ROC 곡선')\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='무작위 예측')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('Receiver Operating Characteristic (ROC)')\n",
    "        ax.legend()\n",
    "        \n",
    "        # Streamlit에 출력\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        st.markdown(f\"### ROC AUC Score: `{roc_auc_score(bank_test['target'], pred):.4f}`\")\n",
    "\n",
    "    with tab3:\n",
    "        st.subheader(\"변수별 중요도\")\n",
    "        \n",
    "        # feature_importance() 호출 시, X_test만 전달\n",
    "        feature_importance = model.feature_importance(bank_test)\n",
    "        print(\"Feature importance for LightGBMLarge model:\")\n",
    "        print(feature_importance)\n",
    "        \n",
    "        # 변수 이름과 중요도를 정렬하여 시각화\n",
    "        importance_df = feature_importance.sort_values(by=\"importance\", ascending=False).head(10)\n",
    "        \n",
    "        # 변수 중요도 시각화\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.barh(importance_df.index, importance_df['importance'], color='skyblue')\n",
    "        ax.set_xlabel('Feature Importance')\n",
    "        ax.set_ylabel('Feature')\n",
    "        ax.set_title('Feature Importance for LightGBMLarge Model')\n",
    "        ax.invert_yaxis()  # 중요도가 높은 순으로 표시\n",
    "        \n",
    "        # Streamlit에 그래프 출력\n",
    "        st.pyplot(fig)\n",
    "\n",
    "    with tab4:\n",
    "       \n",
    "        df2['이탈여부'] = df2['이탈여부'].replace({0: '유지', 1: '이탈'})\n",
    "        feature = st.selectbox(\"분석할 변수 선택\", ['나이', '결혼여부', '총거래금', '회전잔액'])\n",
    "        \n",
    "        fig2, ax2 = plt.subplots()\n",
    "        \n",
    "        if feature == '나이':\n",
    "            df2['recovered_feature'] = df2['나이그룹'].astype(str)\n",
    "        \n",
    "        elif any(feature in col for col in df2.columns if feature != '나이'):\n",
    "            features = [col for col in df2.columns if feature in col]\n",
    "        \n",
    "            if len(features) > 1:\n",
    "                # 원핫 인코딩된 범주형 처리\n",
    "                df2['recovered_feature'] = df2[features].idxmax(axis=1).str.replace(f'{feature}_', '')\n",
    "            else:\n",
    "                # 단일 컬럼 범주형\n",
    "                df2['recovered_feature'] = df2[features[0]]\n",
    "        \n",
    "            # 문자열로 변환 (정렬 목적)\n",
    "            df2['recovered_feature'] = df2['recovered_feature'].astype(str)\n",
    "        \n",
    "        # 범주형: barplot\n",
    "        if feature == '나이' or len(features) > 1:\n",
    "            grouped = df2.groupby(['recovered_feature', '이탈여부']).size().reset_index(name='count')\n",
    "            sns.barplot(data=grouped, x='recovered_feature', y='count', hue='이탈여부', ax=ax2)\n",
    "            ax2.set_title(f'{feature} 별 이탈여부 분포 (범주형)')\n",
    "        \n",
    "        # 연속형: histplot\n",
    "        else:\n",
    "            sns.histplot(data=df2, x=features[0], hue='이탈여부', bins=30, alpha=0.6, ax=ax2)\n",
    "            ax2.set_title(f'{feature} 별 이탈여부 분포 (연속형)')\n",
    "        \n",
    "        st.pyplot(fig2)\n",
    "\n",
    "\n",
    "elif menu == \"모델 추론\":\n",
    "    st.subheader(\"고객 정보 입력을 통한 이탈 예측\")\n",
    "    with st.form(\"predict_form\"):\n",
    "        나이 = st.slider(\"나이 입력\", 0, 100, 30)\n",
    "\n",
    "        # 구간 기준과 레이블\n",
    "        age_bins = [0, 30, 40, 50, 60, 100]\n",
    "        age_labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "        # 나이 → 나이그룹으로 매핑\n",
    "        def age_group(나이):\n",
    "            for i in range(len(age_bins) - 1):\n",
    "                if age_bins[i] <= 나이 < age_bins[i + 1]:\n",
    "                    return age_labels[i]\n",
    "            return age_labels[-1]  # 100세 이상일 경우\n",
    "\n",
    "        나이그룹 = age_group(나이)\n",
    "        회전잔액 = st.slider(\"회전잔액\", 0, 250000, 50000)\n",
    "        성별 = st.selectbox(\"성별\", ['남자', '여자'])  # 성별 입력\n",
    "        결혼여부 = st.selectbox(\"결혼여부\", ['미혼', '기혼'])\n",
    "        submitted = st.form_submit_button(\"예측하기\")\n",
    "\n",
    "    if submitted:\n",
    "        # 성별 원-핫 인코딩 처리\n",
    "        성별_남자 = 1 if 성별 == '남자' else 0\n",
    "        성별_여자 = 1 if 성별 == '여자' else 0  # '여자'일 경우 1, 아니면 0\n",
    "\n",
    "        # 결혼여부 원-핫 인코딩 처리\n",
    "        결혼여부_기혼 = 1 if 결혼여부 == '기혼' else 0\n",
    "        결혼여부_미혼 = 1 if 결혼여부 == '미혼' else 0\n",
    "\n",
    "        # 입력 데이터를 원-핫 인코딩하고, 스케일러 적용\n",
    "        input_data = {\n",
    "            '부양가족수': 0,\n",
    "            '교육수준': 0,\n",
    "            '총거래관계수': 0,\n",
    "            '12개월비활성개월수': 0,\n",
    "            '12개월고객접촉횟수': 0,\n",
    "            '신용한도': df1['신용한도'].median(), #\n",
    "            '회전잔액': 회전잔액, #\n",
    "            '1~4분기총이용금액변화': 0,\n",
    "            '총거래금액': df1['총거래금액'].median(), #\n",
    "            '1~4분기거래횟수변화': 0,\n",
    "            '나이그룹': 나이그룹,\n",
    "            '수입': 0,\n",
    "            '결혼여부_Married': 결혼여부_기혼,\n",
    "            '결혼여부_Single': 결혼여부_미혼,\n",
    "            '결혼여부_Unknown': 0,  # 결혼여부 원-핫 인코딩에서 'Unknown'은 기본값 0\n",
    "            '카드등급_Gold': 0,\n",
    "            '카드등급_Platinum': 0,\n",
    "            '카드등급_Silver': 0,\n",
    "            '성별_M': 성별_남자  # 성별_여자 대신 성별_M 사용 (19개로 맞추기)\n",
    "        }\n",
    "\n",
    "        # 입력값을 DataFrame으로 변환\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "\n",
    "        # 훈련 데이터에서 사용된 feature 순서 확인\n",
    "        feature_names = [\n",
    "            '부양가족수', '교육수준', '총거래관계수', '12개월비활성개월수', '12개월고객접촉횟수', '신용한도', '회전잔액',\n",
    "            '1~4분기총이용금액변화', '총거래금액', '1~4분기거래횟수변화', '나이그룹', '수입', '결혼여부_Married',\n",
    "            '결혼여부_Single', '결혼여부_Unknown', '카드등급_Gold', '카드등급_Platinum', '카드등급_Silver', '성별_M'\n",
    "        ]\n",
    "\n",
    "        # 입력 데이터에서 훈련 데이터의 feature 순서대로 정렬하고, 누락된 feature는 기본값 0으로 채워넣기\n",
    "        input_df = input_df[feature_names]\n",
    "\n",
    "        # 스케일링 처리 (회전잔액, 신용한도, 총거래금액만 스케일링)\n",
    "        features_to_scale = ['신용한도','회전잔액', '총거래금액']  # 훈련 시 사용된 features만 스케일링\n",
    "        input_df[features_to_scale] = scaler.transform(input_df[features_to_scale])\n",
    "\n",
    "        # 예측\n",
    "        pred = model.predict_proba(input_df)   # 모델 예측 (모델에 맞게 데이터를 넣어 예측)\n",
    "        st.write(pred)\n",
    "\n",
    "        # 예측 이탈 가능성 출력\n",
    "        percent = round(pred[1] * 100, 1)  # 예측 결과를 퍼센트로 변환\n",
    "        percent_value = percent.iloc[0]  # Convert to scalar value\n",
    "\n",
    "        st.markdown(f\"### 예측 이탈 가능성: **{percent_value}%**\")\n",
    "\n",
    "        # 이탈 가능성에 따른 메시지 출력\n",
    "        if percent_value > 70:\n",
    "            st.error(\"이탈 가능성이 높습니다.\")\n",
    "        elif percent_value > 40:\n",
    "            st.warning(\"이탈 가능성이 다소 있습니다.\")\n",
    "        else:\n",
    "            st.success(\"이탈 가능성은 낮습니다.\")\n",
    "    \n",
    "elif menu == \"마무리\":\n",
    "    st.markdown(\"\"\"\n",
    "## 🏢 은행 입장에서의 이점\n",
    "\n",
    "- 이탈 위험이 높은 고객을 미리 파악해 타겟 맞춤형 프로모션을 제공할 수 있음\n",
    "- 맞춤형 금융상품 추천으로 고객 충성도를 높이고 이탈을 방지할 수 있음\n",
    "\n",
    "## 🙇‍♀️ 소비자 입장에서의 이점\n",
    "\n",
    "- 본인의 은행 이용 패턴에 맞는 혜택을 제공받을 수 있음\n",
    "- 개선된 고객 경험을 얻을 수 있음\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd5dff-6ec9-4271-b617-50db89c39229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
